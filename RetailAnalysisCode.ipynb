{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b62831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import ntpath\n",
    "import datetime\n",
    "import operator\n",
    "import time\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18e31397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {}\n",
    "files = []\n",
    "\n",
    "def loadFile(path):\n",
    "    global files\n",
    "    global datasets\n",
    "    fileExists = os.path.isfile(path)\n",
    "    if not fileExists:\n",
    "        return False\n",
    "    files.append(path)\n",
    "    filename,fileExtension = os.path.splitext(path)\n",
    "    if '.csv' == fileExtension:\n",
    "        df = pd.read_csv(path)\n",
    "    elif '.xlsx' == fileExtension:\n",
    "        df = pd.read_excel(path)\n",
    "    else:\n",
    "        return False\n",
    "    datasets[ntpath.basename(path)] = df\n",
    "    return True\n",
    "\n",
    "loadFile(\"Features data set.csv\")\n",
    "loadFile(\"sales data-set.csv\")\n",
    "loadFile(\"stores data-set-withDMA.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1991420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features data set:\n",
      "             Store  Temperature   Fuel_Price      MarkDown1      MarkDown2  \\\n",
      "count  8190.000000  8190.000000  8190.000000    4032.000000    2921.000000   \n",
      "mean     23.000000    59.356198     3.405992    7032.371786    3384.176594   \n",
      "std      12.987966    18.678607     0.431337    9262.747448    8793.583016   \n",
      "min       1.000000    -7.290000     2.472000   -2781.450000    -265.760000   \n",
      "25%      12.000000    45.902500     3.041000    1577.532500      68.880000   \n",
      "50%      23.000000    60.710000     3.513000    4743.580000     364.570000   \n",
      "75%      34.000000    73.880000     3.743000    8923.310000    2153.350000   \n",
      "max      45.000000   101.950000     4.468000  103184.980000  104519.540000   \n",
      "\n",
      "           MarkDown3     MarkDown4      MarkDown5          CPI  Unemployment  \n",
      "count    3613.000000   3464.000000    4050.000000  7605.000000   7605.000000  \n",
      "mean     1760.100180   3292.935886    4132.216422   172.460809      7.826821  \n",
      "std     11276.462208   6792.329861   13086.690278    39.738346      1.877259  \n",
      "min      -179.260000      0.220000    -185.170000   126.064000      3.684000  \n",
      "25%         6.600000    304.687500    1440.827500   132.364839      6.634000  \n",
      "50%        36.260000   1176.425000    2727.135000   182.764003      7.806000  \n",
      "75%       163.150000   3310.007500    4832.555000   213.932412      8.567000  \n",
      "max    149483.310000  67474.850000  771448.100000   228.976456     14.313000  \n",
      "Dimensions: 8190x12\n",
      "\n",
      "sales data set:\n",
      "               Store           Dept   Weekly_Sales\n",
      "count  421570.000000  421570.000000  421570.000000\n",
      "mean       22.200546      44.260317   15981.258123\n",
      "std        12.785297      30.492054   22711.183519\n",
      "min         1.000000       1.000000   -4988.940000\n",
      "25%        11.000000      18.000000    2079.650000\n",
      "50%        22.000000      37.000000    7612.030000\n",
      "75%        33.000000      74.000000   20205.852500\n",
      "max        45.000000      99.000000  693099.360000\n",
      "Dimensions: 421570x5\n",
      "\n",
      "stores data set (with DMA):\n",
      "Dimensions: 45x4\n"
     ]
    }
   ],
   "source": [
    "print(\"Features data set:\")\n",
    "print(datasets[\"Features data set.csv\"].describe())\n",
    "print(\"Dimensions: \" + str(datasets[\"Features data set.csv\"].shape[0]) + \"x\" + str(datasets[\"Features data set.csv\"].shape[1]))\n",
    "print()\n",
    "print(\"sales data set:\")\n",
    "print(datasets[\"sales data-set.csv\"].describe())\n",
    "print(\"Dimensions: \" + str(datasets[\"sales data-set.csv\"].shape[0]) + \"x\" + str(datasets[\"sales data-set.csv\"].shape[1]))\n",
    "print()\n",
    "print(\"stores data set (with DMA):\")\n",
    "print(\"Dimensions: \" + str(datasets[\"stores data-set-withDMA.xlsx\"].shape[0]) + \"x\" + str(datasets[\"stores data-set-withDMA.xlsx\"].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a6d0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features data set (updated)\n",
      "             Store  Temperature   Fuel_Price          CPI  Unemployment\n",
      "count  8190.000000  8190.000000  8190.000000  7605.000000   7605.000000\n",
      "mean     23.000000    59.356198     3.405992   172.460809      7.826821\n",
      "std      12.987966    18.678607     0.431337    39.738346      1.877259\n",
      "min       1.000000    -7.290000     2.472000   126.064000      3.684000\n",
      "25%      12.000000    45.902500     3.041000   132.364839      6.634000\n",
      "50%      23.000000    60.710000     3.513000   182.764003      7.806000\n",
      "75%      34.000000    73.880000     3.743000   213.932412      8.567000\n",
      "max      45.000000   101.950000     4.468000   228.976456     14.313000\n"
     ]
    }
   ],
   "source": [
    "markDownColumnNames = []\n",
    "for i in range(1,6):\n",
    "    markDownColumnNames.append('MarkDown' + str(i))\n",
    "\n",
    "datasets[\"Features data set.csv\"] = datasets[\"Features data set.csv\"].drop(markDownColumnNames,axis=1)\n",
    "\n",
    "print(\"Features data set (updated)\")\n",
    "print(datasets[\"Features data set.csv\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67405836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'05/2013': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], '06/2013': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], '07/2013': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]}\n",
      "\n",
      "{'05/2013': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], '06/2013': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45], '07/2013': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]}\n",
      "\n",
      "Are the rows missing a CPI value, also missing an Unemployment value? True\n",
      "Amount of unique missing CPIs: 135\n",
      "Amount of unique missing Unemployment rates: 135\n",
      "Total unique missing values: 270\n"
     ]
    }
   ],
   "source": [
    "#Get the row indicies at which there is a missing value\n",
    "def getNAIndexes(data):\n",
    "    i=0\n",
    "    NAIndexes = []\n",
    "\n",
    "    for row in pd.isna(data):\n",
    "        if row == True:\n",
    "            NAIndexes.append(i)\n",
    "        i+=1\n",
    "    return NAIndexes\n",
    "\n",
    "#Given the missing row indicies, return a dictionary containing key:list(storeNumbers)\n",
    "def getNAInfo(data,indexes):\n",
    "    NAInfo = {}\n",
    "    for index in indexes:\n",
    "        day,month,year = data[index:index+1][\"Date\"].values[0].split('/')\n",
    "        date = month + \"/\" + year\n",
    "        store = data[index:index+1][\"Store\"].values[0]\n",
    "        if date not in NAInfo.keys():\n",
    "            NAInfo[date] = []\n",
    "        if store not in NAInfo[date]:\n",
    "            NAInfo[date].append(store)\n",
    "    return NAInfo\n",
    "\n",
    "#Get the length of a dictionary of lists\n",
    "def lenDictOfLists(dictToCount):\n",
    "    count = 0\n",
    "    for listToCount in dictToCount.values():\n",
    "        count += len(listToCount)\n",
    "    return count\n",
    "\n",
    "missingCPIInfo = getNAInfo(datasets[\"Features data set.csv\"],getNAIndexes(datasets[\"Features data set.csv\"][\"CPI\"]))\n",
    "missingUnemploymentInfo = getNAInfo(datasets[\"Features data set.csv\"],getNAIndexes(datasets[\"Features data set.csv\"][\"CPI\"]))\n",
    "\n",
    "print(missingCPIInfo)\n",
    "print()\n",
    "print(missingUnemploymentInfo)\n",
    "print()\n",
    "print(\"Are the rows missing a CPI value, also missing an Unemployment value? \" + str(missingCPIInfo == missingUnemploymentInfo))\n",
    "print(\"Amount of unique missing CPIs: \" + str(lenDictOfLists(missingCPIInfo)))\n",
    "print(\"Amount of unique missing Unemployment rates: \" + str(lenDictOfLists(missingUnemploymentInfo)))\n",
    "print(\"Total unique missing values: \" + str((lenDictOfLists(missingCPIInfo) + lenDictOfLists(missingUnemploymentInfo))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6a5e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary of missing values to fill in...\n",
      "One of the dictionary builds failed, exiting\n",
      "File exported to modified/Features data set.csv\n"
     ]
    }
   ],
   "source": [
    "monthNumberToMonthName = {\n",
    "    1 : \"January\",\n",
    "    2 : \"February\",\n",
    "    3 : \"March\",\n",
    "    4 : \"April\",\n",
    "    5 : \"May\",\n",
    "    6 : \"June\",\n",
    "    7 : \"July\",\n",
    "    8 : \"August\",\n",
    "    9 : \"September\",\n",
    "    10 : \"October\",\n",
    "    11 : \"November\",\n",
    "    12 : \"December\"\n",
    "}\n",
    "\n",
    "def getColumnIndex(dataFrame,searchTerm,isExactMatch = False): #Return column index number given column name in dataFrame\n",
    "    i=-1\n",
    "    for columnName in list(dataFrame):\n",
    "        if(isExactMatch):\n",
    "            condition = searchTerm == columnName\n",
    "        else:\n",
    "            condition = searchTerm in columnName\n",
    "        i+=1\n",
    "        if condition == True:\n",
    "            return i\n",
    "\n",
    "def buildMissingCPIValues(debug=False): # Build a dictionary containing all missing CPI values from external datasets\n",
    "    global datasets\n",
    "    global missingCPIInfo\n",
    "    missingValues = {}\n",
    "    missingValueErrors = []\n",
    "    success = True\n",
    "    for date,stores in missingCPIInfo.items():\n",
    "        for store in stores:\n",
    "            month,year = date.split('/')\n",
    "            month = \"M\" + str(int(month)).zfill(2)\n",
    "            store = int(store)\n",
    "            targetStoreRow = datasets[\"stores data-set-withDMA.xlsx\"].query(\"Store == @store\")\n",
    "            targetDMA = targetStoreRow.values[0][getColumnIndex(targetStoreRow,\"DMA\")]\n",
    "            targetCPIMapRow = datasets[\"custom-dma-to-cpiArea.csv\"].query(\"DMA == @targetDMA\")\n",
    "            targetCPIArea = targetCPIMapRow.values[0][getColumnIndex(targetCPIMapRow,\"CPI_AreaCode\")]\n",
    "            missingValueFulfilled = False\n",
    "            firstAttemptRan = False\n",
    "            if(type(targetCPIArea) == float): #DMA has missing values, in which case pull from missing values csv\n",
    "                firstAttemptRan = True\n",
    "                cpiRow = datasets[\"custom-dma-to-cpiMissingValuesYearly.csv\"].query(\"DMA == @targetDMA and year == @year\")\n",
    "                if len(cpiRow) > 0:\n",
    "                    cpi = cpiRow.values[0][getColumnIndex(cpiRow,\"value\")]\n",
    "                    missingValueFulfilled = True\n",
    "            if not missingValueFulfilled and not firstAttemptRan:\n",
    "                cpiRowsAreaFiltered = datasets[\"cu.data.0.Current.csv\"][datasets[\"cu.data.0.Current.csv\"]['series_id'].str.contains(targetCPIArea) == True]\n",
    "                cpiRowsDateFiltered = cpiRowsAreaFiltered.query(\"year == @year & period == @month\")\n",
    "                if(len(cpiRowsDateFiltered) <= 0): # Dates have missing values, in which case pull from missing values CSV\n",
    "                    cpiRow = datasets[\"custom-dma-to-cpiMissingValuesYearly.csv\"].query(\"DMA == @targetDMA and year == @year\")\n",
    "                    if len(cpiRow) > 0:\n",
    "                        cpi = cpiRow.values[0][getColumnIndex(cpiRow,\"value\")]\n",
    "                        missingValueFulfilled = True\n",
    "                else: #average all CPI values with the area code\n",
    "                    count = 0\n",
    "                    sum = 0\n",
    "                    for index,row in cpiRowsDateFiltered.iterrows():\n",
    "                        sum += row['value']\n",
    "                        count+=1\n",
    "                    mean = sum/count\n",
    "                    cpi = mean\n",
    "                    missingValueFulfilled = True\n",
    "            if not missingValueFulfilled:\n",
    "                    missingValueErrors.append([store,date])\n",
    "                    success = False\n",
    "            else:        \n",
    "                missingValues[(store,date)] = cpi   \n",
    "    if(debug and not success):\n",
    "        print(\"ERROR: Could not build full CPI dictionary\")\n",
    "        return missingValueErrors\n",
    "    else:\n",
    "        if(not success):\n",
    "            return success\n",
    "        else:\n",
    "            return missingValues\n",
    "def buildMissingUnemploymentRates(debug=False): # Build a dictionary containing all missing unemployment values from external datasets\n",
    "    global datasets\n",
    "    global missingUnemploymentInfo\n",
    "    missingValues = {}\n",
    "    missingValueErrors = []\n",
    "    success = True\n",
    "    for date,stores in missingUnemploymentInfo.items():\n",
    "        for store in stores:\n",
    "            month,year = date.split('/')\n",
    "            month = monthNumberToMonthName[int(month)]\n",
    "            store = int(store)\n",
    "            targetStoreRow = datasets[\"stores data-set-withDMA.xlsx\"].query(\"Store == @store\")\n",
    "            targetDMA = targetStoreRow.values[0][getColumnIndex(targetStoreRow,\"DMA\")]\n",
    "            \n",
    "            targetUnemploymentMapRow = datasets[\"custom-dma-to-unemploymentCounty.csv\"].query(\"DMA == @targetDMA\")\n",
    "            targetState = targetUnemploymentMapRow.values[0][getColumnIndex(targetUnemploymentMapRow,\"UnemploymentState\")]\n",
    "            targetCounty = targetUnemploymentMapRow.values[0][getColumnIndex(targetUnemploymentMapRow,\"UnemploymentCounty\")]\n",
    "            missingValueFulfilled = False\n",
    "            firstAttemptRan = False\n",
    "            if type(targetCounty) == float: # County has missing values, in which case pull from missing values csv\n",
    "                firstAttemptRan = True\n",
    "                unemploymentRateRow = datasets[\"custom-dma-to-unemploymentMissingValues.csv\"].query(\"DMA == @targetDMA and Year == @year and Month == @month\")\n",
    "                if len(unemploymentRateRow) > 0:\n",
    "                    unemploymentRate = unemploymentRateRow.values[0][getColumnIndex(unemploymentRateRow,\"UnemploymentRate\")]\n",
    "                    missingValueFulfilled = True\n",
    "            if not missingValueFulfilled and not firstAttemptRan:\n",
    "                unemploymentRateRow = datasets[\"output.csv\"].query(\"Year == @year & Month == @month & State == @targetState & County == @targetCounty\")\n",
    "                if(len(unemploymentRateRow > 0)):\n",
    "                    unemploymentRate = unemploymentRateRow.values[0][getColumnIndex(unemploymentRateRow,\"Rate\")]\n",
    "                    missingValueFulfilled = True\n",
    "                else: # Missing values for the dates in the dataset, in which case pull from missing values csv\n",
    "                    unemploymentRateRow = datasets[\"custom-dma-to-unemploymentMissingValues.csv\"].query(\"DMA == @targetDMA and Year == @year and Month == @month\")\n",
    "                    if len(unemploymentRateRow) > 0:\n",
    "                        unemploymentRate = unemploymentRateRow.values[0][getColumnIndex(unemploymentRateRow,\"UnemploymentRate\")]\n",
    "                        missingValueFulfilled = True\n",
    "            if not missingValueFulfilled:\n",
    "                missingValueErrors.append([store,date])\n",
    "                success = False\n",
    "            else:        \n",
    "                missingValues[(store,date)] = unemploymentRate\n",
    "    if(debug and not success):\n",
    "        print(\"ERROR: Could not build full unemployment dictionary\")\n",
    "        return missingValueErrors\n",
    "    else:\n",
    "        if(not success):\n",
    "            return success\n",
    "        else:\n",
    "            return missingValues\n",
    "        \n",
    "def fillInFeaturesMissingValues(missingUnemploymentValues,missingCPIValues): # Fill in missing values on Features dataset given dictionaries generated from the above\n",
    "    global datasets\n",
    "    allValuesFilled = True\n",
    "    #Basic error checking to make sure both arguments are in the correct format\n",
    "    if(type(missingUnemploymentValues) != dict or type(missingCPIValues) != dict):\n",
    "        return False\n",
    "    for index,row in datasets[\"Features data set.csv\"].iterrows():\n",
    "        day,month,year = row['Date'].split('/')\n",
    "        date = month + '/' + year\n",
    "        store = int(row['Store'])   \n",
    "        if(pd.isnull(row['Unemployment'])):\n",
    "            if((store,date) in missingUnemploymentValues):\n",
    "                datasets[\"Features data set.csv\"].set_value(index,'Unemployment',missingUnemploymentValues[(store,date)])\n",
    "            else:\n",
    "                allValuesFilled = False    \n",
    "        if(pd.isnull(row['CPI'])):\n",
    "            if((store,date) in missingCPIValues):\n",
    "                datasets[\"Features data set.csv\"].set_value(index,'CPI',missingCPIValues[(store,date)])\n",
    "            else:\n",
    "                allValuesFilled = False\n",
    "    return allValuesFilled\n",
    "\n",
    "loadFile(\"output.csv\")\n",
    "loadFile(\"custom-dma-to-unemploymentCounty.csv\")\n",
    "loadFile(\"custom-dma-to-cpiArea.csv\")\n",
    "loadFile(\"custom-dma-to-unemploymentMissingValues.csv\")\n",
    "loadFile(\"custom-dma-to-cpiMissingValuesYearly.csv\")\n",
    "loadFile(\"cu.data.0.Current.csv\")\n",
    "\n",
    "print(\"Building dictionary of missing values to fill in...\")\n",
    "missingUnemploymentValues = buildMissingUnemploymentRates()\n",
    "missingCPIValues = buildMissingCPIValues()\n",
    "    \n",
    "if(type(missingCPIValues) == dict and type(missingUnemploymentValues) == dict):\n",
    "    print(\"Success\")\n",
    "    print(\"Filling in missing values in Features data set...\")\n",
    "    print(\"NOTE: This will only modify the dataset in memory, not the actual CSV file\")\n",
    "    fillInFeaturesMissingValues(missingUnemploymentValues,missingCPIValues)\n",
    "    if len(datasets[\"Features data set.csv\"].index) == datasets[\"Features data set.csv\"].describe()['Unemployment']['count'] and len(datasets[\"Features data set.csv\"].index) == datasets[\"Features data set.csv\"].describe()['CPI']['count']:\n",
    "        print(\"All CPI and Unemployment missing values have been filled\")\n",
    "    else:\n",
    "        print(\"NOTE: Features dataset still has missing values\")\n",
    "else:\n",
    "    print(\"One of the dictionary builds failed, exiting\")\n",
    "\n",
    "#Export modified Features dataset to file\n",
    "exportPath = 'modified/Features data set.csv'\n",
    "datasets[\"Features data set.csv\"].to_csv(exportPath,index=False)\n",
    "print(\"File exported to \" + exportPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "714c4c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustFeaturesTimeline(startDate,endDate):\n",
    "    global datasets\n",
    "    startDate = datetime.datetime.strptime(startDate, \"%d/%m/%Y\").date()\n",
    "    endDate = datetime.datetime.strptime(endDate, \"%d/%m/%Y\").date()\n",
    "    for index,row in datasets[\"Features data set.csv\"].iterrows():\n",
    "        currentDate = datetime.datetime.strptime(row['Date'], \"%d/%m/%Y\").date()\n",
    "        if currentDate > endDate or currentDate < startDate:\n",
    "            datasets[\"Features data set.csv\"] = datasets[\"Features data set.csv\"].drop([index])\n",
    "\n",
    "adjustFeaturesTimeline(\"05/02/2010\",\"01/11/2012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0b78a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prime\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\prime\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\prime\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\prime\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usefulData = [\n",
    "    'Item',\n",
    "    'Number of consumer units (in thousands)',\n",
    "    'Income before taxes',\n",
    "    'Age of reference person',\n",
    "    'Adults 65 and older',\n",
    "    'Earners',\n",
    "    'Vehicles',\n",
    "    'Percent homeowner',\n",
    "    'Average annual expenditures',\n",
    "    'Food',\n",
    "    'Alcoholic beverages',\n",
    "    'Apparel and services',\n",
    "    'Personal care products and services',\n",
    "    'Tobacco products and smoking supplies'\n",
    "]\n",
    "\n",
    "areas = {}\n",
    "areaInfo = {}\n",
    "\n",
    "loadFile(\"norteast.xlsx\")\n",
    "loadFile(\"midwest.xlsx\")\n",
    "loadFile(\"south.xlsx\")\n",
    "loadFile(\"west.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21ca5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMSA(fileName):\n",
    "    global datasets\n",
    "    global usefulData\n",
    "    global areas\n",
    "    \n",
    "    bufferListOfPlaces = []\n",
    "    bufferDict = {}\n",
    "    for value in datasets[fileName].values:\n",
    "        attribute = value[0]\n",
    "        if attribute in usefulData:\n",
    "            if(attribute == 'Item'): # List of DMAs\n",
    "                bufferListOfPlaces = value[1:]\n",
    "            else:\n",
    "                bufferDict[attribute] = value\n",
    "    if len(bufferListOfPlaces) > 0:\n",
    "        i = 1\n",
    "        for place in bufferListOfPlaces:\n",
    "            place = place.replace('\\n',' ')\n",
    "            for _,value in bufferDict.items():\n",
    "                attribute = value[0]\n",
    "                attributeValue = value[i]\n",
    "                if place not in areas:\n",
    "                    areas[place] = {}\n",
    "                areas[place][attribute] = attributeValue\n",
    "            i+=1\n",
    "    else:\n",
    "        return False\n",
    "                \n",
    "loadMSA(\"midwest.xlsx\")\n",
    "loadMSA(\"norteast.xlsx\")\n",
    "loadMSA(\"south.xlsx\")\n",
    "loadMSA(\"west.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eeead8f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mapStoreNumberToDMA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m DMASpending \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,store \u001b[38;5;129;01min\u001b[39;00m storeSales\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 22\u001b[0m     DMA \u001b[38;5;241m=\u001b[39m \u001b[43mmapStoreNumberToDMA\u001b[49m(index)\n\u001b[0;32m     23\u001b[0m     consumerInfoName \u001b[38;5;241m=\u001b[39m mapDMAToName(datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom-dma-to-consumerArea.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m],DMA)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(consumerInfoName) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mapStoreNumberToDMA' is not defined"
     ]
    }
   ],
   "source": [
    "loadFile(\"custom-dma-to-consumerArea.csv\")\n",
    "\n",
    "sales = datasets[\"sales data-set.csv\"].drop(['Dept','Date','IsHoliday'],axis=1)\n",
    "\n",
    "def getSalesByStore():\n",
    "    global sales\n",
    "    storeSales = {}\n",
    "    for _,row in sales.iterrows():\n",
    "        storeNumber = int(row['Store'])\n",
    "        weeklySales = row['Weekly_Sales']\n",
    "        if storeNumber in storeSales:\n",
    "            storeSales[storeNumber].append(weeklySales)\n",
    "        else:\n",
    "            storeSales[storeNumber] = [weeklySales]\n",
    "    return storeSales\n",
    "\n",
    "storeSales = getSalesByStore() # Very slow\n",
    "DMASpendingPerCapita = {}\n",
    "DMASpending = {}\n",
    "\n",
    "for index,store in storeSales.items():\n",
    "    DMA = mapStoreNumberToDMA(index)\n",
    "    consumerInfoName = mapDMAToName(datasets[\"custom-dma-to-consumerArea.csv\"],DMA)\n",
    "    if type(consumerInfoName) != float:\n",
    "        medianStoreSales = stats.median(storeSales[index])\n",
    "        if DMA not in DMASpendingPerCapita:\n",
    "            DMASpendingPerCapita[DMA] = []\n",
    "            DMASpending[DMA] = []\n",
    "        DMASpendingPerCapita[DMA].append(medianStoreSales)\n",
    "for index,listOfSales in DMASpendingPerCapita.items():\n",
    "    sum = 0\n",
    "    for sale in listOfSales:\n",
    "        sum+=sale\n",
    "    consumerInfoName = mapDMAToName(datasets[\"custom-dma-to-consumerArea.csv\"],index)\n",
    "    DMASpending[index] = sum\n",
    "    DMASpendingPerCapita[index] = sum/areas[consumerInfoName]['Number of consumer units (in thousands)']\n",
    "\n",
    "print(\"Rankings of Overall Spending (Sum of Medians of Stores)\")\n",
    "for index,value in rankDictionary(DMASpending).items():\n",
    "    print(index + \" : \" + str(value))\n",
    "print()\n",
    "print(\"Rankings of Spending per Capita (Sum of Medians of Stores/Number of Customer Units)\")\n",
    "for index,value in rankDictionary(DMASpendingPerCapita).items():\n",
    "    print(index + \" : \" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "808d7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersToTry = [2,3,4]\n",
    "\n",
    "featuresSetForAnalysis = datasets[\"Features data set.csv\"].drop(['IsHoliday','Date'],axis=1)\n",
    "\n",
    "def runKMeans(data,numOfClusters):\n",
    "    kmeans = KMeans(n_clusters=numOfClusters)\n",
    "    kmeans.fit(data)\n",
    "    y_km = kmeans.fit_predict(data)\n",
    "    return y_km\n",
    "\n",
    "for clusterNum in clustersToTry:\n",
    "    exportPath = 'export\\Features data set' + str(clusterNum) + '.csv'\n",
    "    datasetToExport = datasets[\"Features data set.csv\"].assign(cluster = runKMeans(featuresSetForAnalysis,clusterNum).tolist())\n",
    "    datasetToExport.to_csv(exportPath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
